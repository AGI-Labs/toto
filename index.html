<!DOCTYPE html>
<!-- saved from url=(0043)https://vdean.github.io/toto-benchmark.html -->
<html lang="en-US">
  <head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <link rel="shortcut icon" href="https://vdean.github.io/images/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" href="./toto-benchmark_files/style.css">
  <title>Train Offline, Test Online: A Real Robot Learning Benchmark</title>
  <script async="" src="./toto-benchmark_files/analytics.js"></script><script async="" src="./toto-benchmark_files/analytics(1).js"></script><script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    
    ga('create', 'UA-83215168-1', 'auto');
    ga('send', 'pageview');
  </script>
  <style media="all">
    body {
    font-family: "Titillium Web","HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:18px;
    margin-left: auto;
    margin-right: auto;
    width: 100%;
    }
    h1 {
      font-weight:300;
    }
    h2 {
      font-weight:300;
    }
    #primarycontent {
      margin-left: auto;
      WIDTH: expression(document.body.clientWidth > 1000? "1000px": "auto" );
      MARGIN-RIGHT: auto;
      TEXT-ALIGN: left;
      max-width: 1000px;
      LINE-HEIGHT: 1.5; PADDING-TOP: 25px
    }
  </style>
</head>
<body>
  <!-- add navigation bar -->
  <div id="topnav">
    <ul class="nav-list">
      <li><a class="nav-link" href="https://github.com/AGI-Labs/toto_benchmark/tree/release">Code</a></li>
      <li><a class="nav-link" href="#code">Dataset</a></li>
      <li><a class="nav-link" href="#overview">Overview</a></li>
      <li><a class="nav-link" href="#results">Results</a></li>
      <li><a class="nav-link" href="submission.html">Submission</a></li>
      <!-- link a new submissions html page -->
    </ul>

  </div>
  
  <div id="primarycontent">
    <center><h1><strong>Train Offline, Test Online: A Real Robot Learning Benchmark</strong></h1></center>
    <center><h2>
    <span style="font-size:20px;">
        <a href="https://gaoyuezhou.github.io/" target="_blank">Gaoyue Zhou*<span><sup>1</sup></span></a>&nbsp;&nbsp;&nbsp;
        <a href="https://vdean.github.io/" target="_blank">Victoria Dean*<span><sup>1</sup></span></a>&nbsp;&nbsp;&nbsp;
        <a href="https://mohansrirama.com/" target="_blank">Mohan Kumar Srirama<span><sup>1</sup></span></a>&nbsp;&nbsp;&nbsp;
        <a href="https://aravindr93.github.io/" target="_blank">Aravind Rajeswaran<span><sup>2,5</sup></span></a>&nbsp;&nbsp;&nbsp;
        <a href="https://jyopari.github.io/" target="_blank">Jyothish Pari<span><sup>3</sup></span></a>&nbsp;&nbsp;&nbsp;
   </span> <br>
    <span style="font-size:20px;">
      <a href="" target="_blank">Kyle Hatch<span><sup>4</sup></span></a>&nbsp;&nbsp;&nbsp;
      <a href="https://www.linkedin.com/in/aryan-jain-9101/" target="_blank">Aryan Jain<span><sup>5</sup></span></a>&nbsp;&nbsp;&nbsp;
      <a href="https://cs.stanford.edu/~tianheyu/" target="_blank">Tianhe Yu<span><sup>4</sup></span></a>&nbsp;&nbsp;&nbsp;
      <a href="https://people.eecs.berkeley.edu/~pabbeel/" target="_blank">Pieter Abbeel<span><sup>5</sup></span></a>&nbsp;&nbsp;&nbsp;
      <a href="https://www.lerrelpinto.com/" target="_blank">Lerrel Pinto<span><sup>3</sup></span></a>&nbsp;&nbsp;&nbsp;
      <a href="https://ai.stanford.edu/~cbfinn/" target="_blank">Chelsea Finn<span><sup>4</sup></span></a>&nbsp;&nbsp;&nbsp;
      <a href="http://www.cs.cmu.edu/~abhinavg/" target="_blank">Abhinav Gupta<span><sup>1</sup></span></a>&nbsp;&nbsp;&nbsp;

    </span>
       </h2>
        <h2>
        <span style="font-size:12px;">
          <sup>1</sup> Carnegie Mellon University, Robotics Institute&nbsp;&nbsp;&nbsp;   
          <sup>2</sup> University of Washington&nbsp;&nbsp;&nbsp;   
          <sup>3</sup> New York University&nbsp;&nbsp;&nbsp;
          <!-- <br> -->
          <sup>4</sup> Stanford University&nbsp;&nbsp;&nbsp;   
          <sup>5</sup> University of California, Berkeley&nbsp;&nbsp;&nbsp;   
        </span>
        </h2>
        <div class="rowfive">
          <div class="columnfive">
            <img src="./toto-benchmark_files/ri_logo.jpeg" alt="ri" style="width:auto; height:50px; padding: 20px">
            <img src="./toto-benchmark_files/uw_logo.png" alt="uw" style="width:auto; height:50px; padding: 20px">
            <img src="./toto-benchmark_files/nyu_logo.png" alt="nyu" style="width:auto; height:50px; padding: 20px">
            <img src="./toto-benchmark_files/stanford_logo.jpeg" alt="stanford" style="width:auto; height:50px; padding: 20px">
            <img src="./toto-benchmark_files/bair_logo.png" alt="bair" style="width:auto; height:50px; padding: 20px">
          </div>
        </div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/QCgZ-m1o_Pw" title="YouTube video player" 
          frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
          allowfullscreen>
        </iframe>
        <h2>
        <span style="font-size:20px;">In Submission to IEEE International Conference on Robotics and Automation (ICRA), 2023</span>
        </h2>
    <div id="code">
        <br> 
    
    <center>
      <h2>
        <span style="font-size:25px;">
          <!-- <a href="" target="_blank"><b>Paper</b></a>   -->
          <a href="https://github.com/AGI-Labs/toto_benchmark/tree/release" target="_blank"><b>Code</b></a>  
          <a href="https://drive.google.com/drive/folders/1JGPGjCqUP4nUOAxY3Fpx3PjUQ_loo7fc?usp=share_link" target="_blank"><b>Dataset</b></a>
 
        </span>
      </h2>
      </div>
    </center>
    
    <!-- <left><img src="./toto-benchmark_files/tst.gif" width="480px" height="400px"></left>
    <right><img src="./toto-benchmark_files/toto_teaser.png" width="800px"><br><br></right> -->


    <p>
    </p><div width="500"><p>
      <table align="center" width="800px">
          <tbody><tr>
          <td>
    <p align="justify" width="20%">
      Three challenges limit the progress of robot learning research: robots are expensive (few labs can participate), everyone uses different robots (findings do not generalize across labs), and we lack internet-scale robotics data. We take on these challenges via a new benchmark: <b>T</b>rain <b>O</b>ffline, <b>T</b>est <b>O</b>nline (<b>TOTO</b>). TOTO provides remote users with access to shared robots for evaluating methods on common tasks and an open-source dataset of these tasks for offline training. Its manipulation task suite requires challenging generalization to unseen objects, positions, and lighting. We present initial results on TOTO comparing five pretrained visual representations and four offline policy learning baselines, remotely contributed by five institutions. The real promise of TOTO, however, lies in the future: we release the benchmark for additional submissions from any user, enabling easy, direct comparison to several methods without the need to obtain hardware or collect data.
    </p></td></tr></tbody></table>
    </p>
    <div id="overview">
    <p></p>
    <hr>

    <!-- Main content -->

      <h1 align="center">Benchmark Overview</h1>
      
      
      <img src="./toto-benchmark_files/toto_teaser.png" alt="toto_teaser" style="width:80%; width:800px">
      <p>
      </p><div width="500"><p>
        <table align="center" width="800px">
          <tbody><tr>
            <td>
              <p align="justify" width="20%">
                TOTO has two key components: (a) a large-scale offline manipulation dataset to train imitation learning and offline RL algorithms; (b) a shared hardware setup where users can evaluate their methods now and going forward. Because all TOTO participants train using the same publicly-released dataset and evaluate on shared hardware, the benchmark provides a fair apples-apples comparison. We present the TOTO benchmark design as well as initial methods contributed by benchmark beta testers across the country.
              </p></td></tr></tbody></table>
            </p>
    </div>
            
    <div id="results">
            <hr>

      <h1 align="center">Results</h1>
      
      <div width="500"><p>
        <table align="center" width="800px">
          <tbody><tr>
            <td>
              <p align="justify" width="20%">
                The task suite consists of two household manipulation tasks that humans encounter on a daily basis: pouring and scooping. Each involves challenging variations in objects, position, and more.
              </p></td></tr></tbody></table>
            </p>
            
            <div class="row">
              <div class="column">
                <h2>Pouring</h2>
                <img src="./toto-benchmark_files/test_video_pour.gif" alt="toto" style="width: 80%;">
              </div>
              <div class="column">
                <h2>Scooping</h2>
                <img src="./toto-benchmark_files/bc_video_scoop_train4.gif" alt="toto" style="width: 80%;">
              </div>
            </div>
            
            <p>
              <table align="center" width="800px">
                <tbody><tr>
                  <td>
                    <p align="justify" width="20%">
                      We highlight the value of TOTO by running two sets of experiments:
                      (a) what is a good visual representation for manipulation?
                      (b) what is a good offline algorithm for policy learning?
                      For these experiments, we use baseline implementations solicited from several labs.
                    </p></td></tr></tbody></table>
                  </p>
                  
                  <div class="row">
                    
                    <div class="column">
                      <img src="./toto-benchmark_files/pouring-insertionsuccess_rates_vision_plots.png" alt="pouring_results" style="width: 80%;">
                    </div>
                    <div class="column">
                      <img src="./toto-benchmark_files/scooping-pouring-insertionsuccess_rates_vision_plots.png" alt="toto" style="width:80%">
                    </div>
                  </div>
                  
                  <p>
                    <table align="center" width="800px">
                      <tbody><tr>
                        <td>
                          <p align="justify" width="20%">
                            Vision representation comparison with BC. Models trained on our data (left of dashed line) perform better than generic ones (right of dashed line), and results tend to be better for training object locations than unseen test locations.
                            These results show that finetuning the MoCo model on our data outperforms the generic version, as expected. MoCo (In-Domain) achieves the highest success rate and average reward on both scooping and pouring, followed by BYOL, the other in-domain model. In general, the relative performance between models is mostly consistent across scooping and pouring. Resnet50 and MoCo (Generic) perform slightly better on pouring than on scooping.
                            The figure also visualizes performance differences due to object locations. Locations seen during training perform better, as expected, but performance does not degrade significantly, suggesting that the representations have a generalizable notion of where the target object is. Surprisingly, the two representations trained on our data (MoCo (In-Domain) and BYOL) perform equally good or even slightly better on unseen locations for scooping.
                          </p></td></tr></tbody></table>
                        </p>
                        
                        <div class="row">
                          
                          <div class="column">
                            <img src="./toto-benchmark_files/pouring-insertionsuccess_rates_policy_plots.png" alt="pouring_results" style="width: 80%;">
                          </div>
                          <div class="column">
                            <img src="./toto-benchmark_files/scooping-pouring-insertionsuccess_rates_policy_plots.png" alt="toto" style="width:80%">
                          </div>
                        </div>
                        
                        <p>
                          <table align="center" width="800px">
                            <tbody><tr>
                              <td>
                                <p align="justify" width="20%">
                                  We find that VINN performs the best in train locations. We also note that offline-RL approaches (especially IQL) achieve some success unlike in RB2. This is likely due to a larger and more diverse dataset than RB2, which contributes to better offline RL performance.
                                  We found that the scooping proves challenging due to a non-markovian aspect of the task: the spoon is above the bowl both before and after scooping. Thus we would expect open-loop methods (BC, VINN) and those with history (DT) to perform better than others in this setting. While BC and VINN achieve competitive performance on scooping, DT only achieves moderate success on scooping and does not see any positive rewards on pouring. Meanwhile, IQL provides decent performance without history on a non-markovian task.
                                  Comparing the train and test location results for policy learning proves interesting. VINN performs the best on train locations, but it struggles on unseen locations, since it selects actions using the nearest neighbor trajectory from the training data. All other methods also experience some level of degradation when moving to unseen locations, leaving one clear direction for method improvement using TOTO.  
                                </p></td></tr></tbody></table>
                              </p>
                              
                            </div>
                            
                          </div>
                        </div> 
                        
                        <!-- <div id="submission">
                          <hr>
                          <h1 align="center">Submission</h1>

                          <p>
                            <table align="center" width="800px">
                              <tbody><tr>
                                <td>
                                  <p align="justify" width="20%">
                                    
                                    We invite the community to submit their methods to TOTO benchmark.
                                    We allow submissions to contain either
                                    <ol>
                                      <li> A pre-trained visual representation model </li>
                                      <li> An agent policy either which uses a custom visual representation or the ones we provide </li>
                                    </ol>
                                    
                                    of both standalone vision representations and agent policies 
                                    You can find below the steps to submit your method.
                                    <p></p>
                                    Pre-Training
                                    <ol>
                                      <li>Download the dataset <a href="https://drive.google.com/drive/folders/1pDD8c2cUtLFtyAScL5hzJBwnKWsnKnXN?usp=sharing" target="_blank"><b>here</b></a>.</li>
                                      <li>Use the starter training code <a href="https://github.com/AGI-Labs/TOTO_starter" target="_blank"><b>here</b></a> to train your method on the dataset.</li>
                                      <li>Follow these packaging <a href="https://github.com/AGI-Labs/TOTO_starter" target="_blank"><b>instructions</b></a> to wrap your method in the right format for evaluation.</li>
                                      <li>Submit your wrapped method for evaluation using this google <a href="https://docs.google.com/forms/d/e/1FAIpQLScrfl3ugtX2U8I8Zv64ZlniHc9pOLZScIn-OQMg5xrj0WwLYA/viewform?usp=sf_link" target="_blank"><b>form</b></a>.</li>
                                      <li>We will evaluate your method on the robot hardware and update your position on the leaderboard.</li>  
                                    </ol>
                                  </p></td></tr></tbody></table>
                                </p>
                        </div> -->
                          <div style="width:800px; margin:auto; margin-bottom:100px">
                            <!-- <br><h1 style="font-size:50px">Train Offline, Test Online: A Real Robot Learning Benchmark</h1> -->
                          </div>
                          <div style="position: static !important;"></div><div id="pt-ext-root"></div>
                        </body>
                        </html>
